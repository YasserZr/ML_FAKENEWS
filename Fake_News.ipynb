{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32679507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12c6bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "fake_data = pd.read_csv(\"Fake.csv\")\n",
    "true_data = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c289253-d930-4335-9b6e-c898bb19b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (removing special characters, extra spaces)\n",
    "def clean_text(text):\n",
    "    text = text.str.replace(r\"[^\\w\\s]\", \"\", regex=True)  # Remove special characters\n",
    "    text = text.str.lower()  # Convert to lowercase\n",
    "    text = text.str.strip()  # Remove leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "fake_data[\"text\"] = clean_text(fake_data[\"text\"])\n",
    "true_data[\"text\"] = clean_text(true_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "87f2b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to the datasets: 1 for fake, 0 for real\n",
    "fake_data[\"label\"] = 1\n",
    "true_data[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eaa5b8c5-a660-4e5e-b48b-3aaa03f6e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "data = pd.concat([fake_data, true_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d91812e-d000-4c4f-bd27-adcfc1d6a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to mix fake and real samples\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f731ba02-2cb1-4568-b633-ed5b6bb2b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.dropna(subset=[\"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba1698b6-b376-4c99-aed3-0f55f6f23ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'text' and 'label' columns\n",
    "X, y = data[\"text\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "965d3051-1496-4d6a-a2dc-44876d39f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90e6d900-60da-4ca4-9c6a-1fafdb8c9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "818ab51b-7eee-483f-bbe6-9d04e5f06acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"LinearSVC\": LinearSVC(random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9f00cea4-0e3f-4750-b615-1d07c9e279c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearSVC...\n",
      "LinearSVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4284\n",
      "           1       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "LinearSVC Confusion Matrix:\n",
      "[[4272   12]\n",
      " [  24 4672]]\n",
      "Training Naive Bayes...\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      4284\n",
      "           1       0.96      0.94      0.95      4696\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[4102  182]\n",
      " [ 285 4411]]\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4284\n",
      "           1       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[4241   43]\n",
      " [  64 4632]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    print(f\"{model_name} Classification Report:\\n{classification_report(y_test, predictions)}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{confusion_matrix(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "531cc94a-e26b-40cd-a1c0-7a8469cadf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the models on new text\n",
    "def predict_new_text(file_path, vectorizer, models):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Clean and vectorize the text\n",
    "    cleaned_text = clean_text(pd.Series(text))\n",
    "    vectorized_text = vectorizer.transform(cleaned_text)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        prediction = model.predict(vectorized_text)\n",
    "        print(f\"{model_name} Prediction: {'FAKE' if prediction[0] == 1 else 'REAL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba2d1e3c-29e2-48d1-8fdc-16a7845b023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Prediction: REAL\n",
      "Naive Bayes Prediction: REAL\n",
      "Logistic Regression Prediction: REAL\n"
     ]
    }
   ],
   "source": [
    "# Test new input\n",
    "predict_new_text(\"mytest.txt\", vectorizer, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
